{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0306c45-3e21-441c-8ee8-bddc05899c5d",
   "metadata": {},
   "source": [
    "\n",
    "<h4>1.What is NLTK ?</h4>\n",
    "    <p>-NLTK is a toolkit build for working with NLP in Python. It provides us various text processing libraries with a lot of test datasets. A variety of tasks can be performed using NLTK such as tokenizing, parse tree visualization, etc\n",
    "    \n",
    "    -Tokenization is one of the first step in any NLP pipeline.\n",
    "    -Tokenization is nothing but splitting the raw text into small chunks of words or sentences, called tokens.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bfb97e-0e40-400b-9048-a3a0dade6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba5e074-1c34-40df-a6dc-cc295f48aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brawn', 'fox', 'jump', 'over', 'the', 'would', '?']\n"
     ]
    }
   ],
   "source": [
    "user_input = \"the quick brawn fox jump over the would?\"\n",
    "result = word_tokenize(user_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267a0e4-19de-4716-80f1-2a74c8154572",
   "metadata": {},
   "source": [
    " <h3>LowerCasing</h3>\n",
    "    <p>-Lowercasing in NLP is the process of converting all text to lowercase to ensure that the model\n",
    "     doesn't treat the same word differently because of its capitalization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b874164-3bf3-47d2-9461-cc68956b3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE QUICK BRAWN FOX JUMP OVER THE WOULD?\n"
     ]
    }
   ],
   "source": [
    "user_input = 'the quick brawn fox jump over the would?'\n",
    "result= user_input.upper()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d1d78-8f65-48ff-a658-cc5c94298334",
   "metadata": {},
   "source": [
    "<h3>Stemming</h3>\n",
    "<p>Stemming is a common technique used in NLP (Natural Language Processing) to reduce a word to\n",
    "its root form by removing suffixes or prefixes.\n",
    "    • The resulting root word is called a stem.\n",
    "    • The purpose of stemming is to reduce the number of words that a machine learning model needs to\n",
    "analyze</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcef14f7-0140-4280-8485-d4480baf74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c3dc7d-7e26-4fb1-a7af-c71b89d087a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "quick\n",
      "brawn\n",
      "fox\n",
      "jump\n",
      "over\n",
      "the\n",
      "would?\n"
     ]
    }
   ],
   "source": [
    "input = \"THE QUICK BRAWN FOX JUMP OVER THE WOULD?\"\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for word in input.split():\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d9a80-dd65-4759-bcf3-a110e0259da3",
   "metadata": {},
   "source": [
    "<h3>Lemmatization</h3>\n",
    "    <p>-Lemmatization is another technique used in NLP to reduce a word to its base or dictionary form,\n",
    "     called a lemma.\n",
    "    -Unlike stemming, which simply removes suffixes or prefixes, lemmatization takes into account the\n",
    "     context of the word and its part of speech (POS) tag to produce a more accurate base form.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25b688f-5b29-437c-a0a7-ab72a3e62665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3116b4-b0df-4e48-a622-56b6bb762b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD?']\n",
      "THE\n",
      "QUICK\n",
      "BRAWN\n",
      "FOX\n",
      "JUMP\n",
      "OVER\n",
      "THE\n",
      "WOULD?\n"
     ]
    }
   ],
   "source": [
    "input_lemma = 'THE QUICK BRAWN FOX JUMP OVER THE WOULD?'\n",
    "lemmatization = WordNetLemmatizer()\n",
    "token_word = input_lemma.split()\n",
    "print(token_word)\n",
    "for word in token_word:\n",
    "    print(lemmatization.lemmatize(word,pos = 'v'))#pos = part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d56c1-aaec-4c76-9b8d-47b6fb1939c0",
   "metadata": {},
   "source": [
    "<h3>Stopword</h3>\n",
    "    <p>• In Natural Language Processing (NLP), stopwords are words that are frequently used in a language,\n",
    "        but usually do not carry much meaning and can be removed from a text without significantly altering\n",
    "        its overall meaning.\n",
    "    • These words include common pronouns, prepositions, and conjunctions<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46db1ac3-1457-4b41-b6be-20c244396479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43d3eeaa-c05f-4d46-b9f4-85de6bdfd201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n",
      "['THE', 'QUICK', 'BRAWN', 'FOX', 'JUMP', 'OVER', 'THE', 'WOULD', '?']\n"
     ]
    }
   ],
   "source": [
    "input_stop = 'THE QUICK BRAWN FOX JUMP OVER THE WOULD?'\n",
    "tokens = word_tokenize(input_stop)\n",
    "stop_words = set(stopwords.words('English'))\n",
    "filtered_sentence=[]\n",
    "for w in tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "    print(tokens)\n",
    "    print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb892b6c-cc17-49a7-8449-4940c7543b81",
   "metadata": {},
   "source": [
    "<h3>Punctions Mark Removal</h3>\n",
    "    <p>• Most common text processing technique is removing punctuations from the textual data.\n",
    "    • The punctuation removal process will help to treat each text equally.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5fedcccb-86fd-44fd-9776-318592923bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87518e81-c36f-4d91-8052-6a1f8ed359cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey JERRY IS A NOTORIOUS KID\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    # remove punctuation marks using string.punctuation\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    # tokenize the text into words\n",
    "    tokens = nltk.word_tokenize(no_punct)\n",
    "    # join the tokens into a string\n",
    "    text_no_punct = \" \".join([token for token in tokens])\n",
    "    return text_no_punct\n",
    "\n",
    "text = \" hey! JERRY IS A NOTORIOUS KID. ?\"\n",
    "text_no_punct = remove_punctuation(text)\n",
    "print(text_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e2af59b0-b922-44f2-a9da-63db4ca788aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \" \".join([c for c in text if c not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(no_punct)\n",
    "    text_no_punct = \" \".join([token for token in tokens])\n",
    "text = \" hey! JERRY IS AN NOTORIOUS KIT.? \"\n",
    "text_no_punct = remove_punctuation(text)\n",
    "print(text_no_punct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
